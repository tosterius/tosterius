---
layout: post
title: Fully Convolutional Networks (FCN)
subtitle : Fully Convolutional Networks for Semantic Segmentation
tags: [DL]
author: Arthur
comments : False
---

#### Conversion Fully Connected Layer to Convolutional layer
<br>

For any CONV layer there is an FC layer that implements the
same forward function. The weight matrix would be a large
matrix that is mostly zero except for at certain blocks (due to
local connectivity) where the weights in many of the blocks
are equal (due to parameter sharing) Source: [cs231n](http://cs231n.github.io/convolutional-networks/#convert).

<br>
If we take a look at VGG16 neural architecture we can see that the output 
dimmenson of the last convolutional layer is $$7 \times 7 \times 512$$.
The next leayer is FC layer and has dimension $$1\times1\times4096$$.
We can just create $$4096$$ filters of size $$7\times7$$ to get the same output.

<br>
![sample image]({{ site.baseurl }}/assets/img/blog/fc_to_conv_1.png)


#### FCN for Smantic segmentation

Given neural network trained on classification task.
The main idea is to substitute the last fully connected layer by convolution layer.
If we then scale up this last layer to our input image size we get a segmentation mask.
These direct prediction of FCN are typically in low resolution, 
because the resolution of output feature maps is downsampled. 

<br>

#### FCN-32, FCN-16, FCN-8
- 

<br>

<h2>1. Code </h2>
You can add highlighting for code in `highlight.scss`.

{% highlight python %}
# test function
def test :
    print('hello world!')
{% endhighlight %}

<br>

<h2>2. Quotes</h2>
{% highlight html %}
> Hello World, This is quotes!
{% endhighlight %}
> Hello World, This is quotes!

<br>

<h2>3. `Backtick`</h2>
{% highlight html %}
`Grape-Theme`
{% endhighlight %}
`Grape-Theme`

